# -*- coding: utf-8 -*-
"""Final Deep Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cZ81zSHzDOKQeFkVlyYY8WH6acTR4FQk

# Statistics:
1. Total number of images: 2,496,738
2. Number of real images: 964,989
3. Number of fake images: 1,531,749
4. Number of generators used for fake images: 25 (including 13 GANs, 7 Diffusion, and 5 miscellaneous generators)
5. Number of sources used for real images: 8
6. Categories included in the dataset: Human/Human Faces, Animal/Animal Faces, Places, Vehicles, Art, and other real-life objects
7. Image Resolution: 200 x 200

# Load Data
"""

# Download kaggle.json file
from google.colab import files
files.upload()

# Move the kaggle.json file to the correct folder
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d birdy654/cifake-real-and-ai-generated-synthetic-images

!unzip cifake-real-and-ai-generated-synthetic-images.zip

"""# Just to learn about the data set"""

import os
import shutil
import re
from tqdm import tqdm
from collections import defaultdict
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image

# Define your source and destination folders
source_dirs = ['train/FAKE', 'train/REAL', 'test/FAKE', 'test/REAL']
dest_root = 'organized_dataset_by_class'

# Regex to extract class number
pattern = re.compile(r'\((\d+)\)')

# Helper function to extract class from filename
def get_class_number(filename):
    match = pattern.search(filename)
    if match:
        return int(match.group(1))
    else:
        return 1

# Dictionary to count images per class
counter = defaultdict(int)

# Start organizing
for src in tqdm(source_dirs, desc="Organizing dataset"):
    # Determine if FAKE or REAL
    label = 'FAKE' if 'FAKE' in src else 'REAL'

    # Go through all files
    for filename in os.listdir(src):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            class_num = get_class_number(filename)
            dest_folder = os.path.join(dest_root, label, f'class_{class_num}')
            os.makedirs(dest_folder, exist_ok=True)
            src_path = os.path.join(src, filename)
            dest_path = os.path.join(dest_folder, filename)
            shutil.copy(src_path, dest_path)

            # Update counter
            counter[(label, class_num)] += 1

# Print summary
print("\nSummary Report:")
for (label, class_num), count in sorted(counter.items()):
    print(f"{label} - Class {class_num}: {count} images")

# Show one random image from each class
print("\nShowing one image from each class:")

for (label, class_num) in sorted(set(counter.keys())):
    folder_path = os.path.join(dest_root, label, f'class_{class_num}')
    images = os.listdir(folder_path)
    if images:
        random_image = random.choice(images)
        img_path = os.path.join(folder_path, random_image)
        img = mpimg.imread(img_path)
        plt.figure(figsize=(3,3))
        plt.imshow(img)
        plt.title(f'{label} - Class {class_num}')
        plt.axis('off')
        plt.show()

import os

train_dir = '/content/train'
test_dir = '/content/test'

#  Ù„Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
def count_images_in_dir(directory):
    image_count = 0
    for subdir, _, files in os.walk(directory):
        for file in files:
            if file.endswith(('.jpg', '.png', '.jpeg')):
                image_count += 1
    return image_count

# Ø­Ø³Ø§Ø¨ Ø§Ù„ØµÙˆØ± ÙÙŠ train Ùˆ test
train_images = count_images_in_dir(train_dir)
test_images = count_images_in_dir(test_dir)

print(f"Number of images in train: {train_images}")
print(f"Number of images in test: {test_images}")

"""# Some Functions"""

import plotly.graph_objects as go

def plot_training_history_with_plotly(history):
    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=list(range(1, len(history.history['accuracy']) + 1)),
        y=history.history['accuracy'],
        mode='lines',
        name='Train Accuracy'
    ))

    fig.add_trace(go.Scatter(
        x=list(range(1, len(history.history['val_accuracy']) + 1)),
        y=history.history['val_accuracy'],
        mode='lines',
        name='Validation Accuracy'
    ))

    fig.update_layout(
        title='Model Accuracy',
        xaxis_title='Epoch',
        yaxis_title='Accuracy',
        legend=dict(x=0, y=1),
    )

    fig.show()

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=list(range(1, len(history.history['loss']) + 1)),
        y=history.history['loss'],
        mode='lines',
        name='Train Loss'
    ))

    fig.add_trace(go.Scatter(
        x=list(range(1, len(history.history['val_loss']) + 1)),
        y=history.history['val_loss'],
        mode='lines',
        name='Validation Loss'
    ))

    fig.update_layout(
        title='Model Loss',
        xaxis_title='Epoch',
        yaxis_title='Loss',
        legend=dict(x=0, y=1),
    )

    fig.show()

"""# Augmentation

"""

from PIL import Image
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import os
import matplotlib.pyplot as plt
from tensorflow.keras import callbacks
from tensorflow.keras.callbacks import ModelCheckpoint

img_path = '/content/train/REAL/0000 (3).jpg'
img = Image.open(img_path)

img_array = np.array(img)
print(img_array.shape)

import os
import random
import shutil

train_dir = '/content/train'         # Ù…Ø¬Ù„Ø¯ train ÙÙŠÙ‡ Real Ùˆ Fake
val_dir = '/content/validation'      # Ù…Ø¬Ù„Ø¯ Ø¬Ø¯ÙŠØ¯ Ø­Ù†Ù†Ø´Ø¦Ù‡ Ù„Ùˆ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ validation
os.makedirs(val_dir, exist_ok=True)

classes = ['REAL', 'FAKE']
val_ratio = 0.2  # Ù†Ø³Ø¨Ø© 20% Ù„Ù„Ù€ validation

for cls in classes:
    cls_train_path = os.path.join(train_dir, cls)
    cls_val_path = os.path.join(val_dir, cls)
    os.makedirs(cls_val_path, exist_ok=True)

    all_images = [
        fname for fname in os.listdir(cls_train_path)
        if os.path.isfile(os.path.join(cls_train_path, fname))
    ]

    # Random selection of 10% of images
    val_count = int(len(all_images) * val_ratio)
    selected_for_val = random.sample(all_images, val_count)

    print(f'ðŸ“¦ {cls}: Ù†Ù‚Ù„ {val_count} ØµÙˆØ±Ø© Ù…Ù† Ø£ØµÙ„ {len(all_images)} Ø¥Ù„Ù‰ validation')

    # Transfer images
    for fname in selected_for_val:
        src = os.path.join(cls_train_path, fname)
        dst = os.path.join(cls_val_path, fname)
        shutil.move(src, dst)

# Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„fake ÙˆØ§Ù„ real ÙÙŠ Ø§Ù„ train
import os


class_counts = {}

for class_name in os.listdir(train_dir):
    class_path = os.path.join(train_dir, class_name)
    if os.path.isdir(class_path):
        count = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])
        class_counts[class_name] = count

# Print the results
for class_name, count in class_counts.items():
    print(f"{class_name}: {count} ØµÙˆØ±Ø©")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1.ImageDataGenerators

# Augmentation + Normalization Ù„Ù„Ù€ train
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# ÙÙ‚Ø· Normalize Ù„Ù„Ù€ val Ùˆ test
val_test_datagen = ImageDataGenerator(rescale=1./255)

# 2.Load data from folders

train_path = '/content/train'
val_path = '/content/validation'
test_path = '/content/test'

# train data
train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(32, 32),
    batch_size=32,
    class_mode='binary',
    shuffle=True
)

# validation data
val_generator = val_test_datagen.flow_from_directory(
    val_path,
    target_size=(32, 32),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

# test data
test_generator = val_test_datagen.flow_from_directory(
    test_path,
    target_size=(32, 32),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

"""# Modeling

"""

!pip install visualkeras

from PIL import Image
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import os
import matplotlib.pyplot as plt
from tensorflow.keras import callbacks
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D,Flatten,MaxPooling2D,BatchNormalization, Dropout
import visualkeras

# ØªØ­Ø¯Ø¯ ÙˆÙŠÙ† Ø¨Ø¯Ùƒ ØªØ­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ´Ùˆ ØªØ±Ø§Ù‚Ø¨
checkpoint = ModelCheckpoint(
    filepath='best_model.keras',    # Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù„ÙŠ Ø¨Ø¯Ùƒ ØªØ­ÙØ¸ ÙÙŠÙ‡
    monitor='val_accuracy',          # Ø§Ù„Ø´ÙŠØ¡ Ø§Ù„Ù„ÙŠ Ø¨Ø¯Ùƒ ØªØ±Ø§Ù‚Ø¨Ù‡ (Ù…Ø«Ù„Ø§ Ø£Ù‚Ù„ Ù‚ÙŠÙ…Ø© Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„ÙØ§Ù„ÙŠØ¯ÙŠØ´Ù†)
    mode='max',                  # Ù„Ù…Ø§ ØªÙƒÙˆÙ† Ø¨Ø¯Ùƒ Ø£Ù‚Ù„ Ø®Ø³Ø§Ø±Ø© (min) Ø£Ùˆ Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø© (max)
    save_best_only=True,         # ÙŠØ­ÙØ¸ Ø¨Ø³ Ù„Ù…Ø§ ÙŠØªØ­Ø³Ù†
    verbose=1                    # ÙŠØ¸Ù‡Ø±Ù„Ùƒ ÙƒÙ„ Ù…Ø±Ø© ÙŠØ­ÙØ¸ ÙÙŠÙ‡Ø§
)

"""## CIFAKE Model"""

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32,32,3)))
model.add(MaxPooling2D())
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D())
model.add(BatchNormalization())
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
early = callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, mode='auto', restore_best_weights=True, patience=5)

# Display model summary
model.summary()

model.build()
visualkeras.layered_view(model, scale_xy=5 ,legend=True)

# fitting the model
history = model.fit(
    train_generator,               # Training data with Augmentation
    epochs=100,                     # number of Epochs
    validation_data=val_generator,  # validation data without Augmentation
    verbose=1 ,
    callbacks=[early,checkpoint]
)

model.save('CIFAKE.keras')

"""### Evaluation of Model1 "CIFAKE"
"""

from tensorflow.keras.models import load_model
model = load_model('/content/CIFAKE.keras')

val_loss, val_accuracy = model.evaluate(test_generator)
print(f'ðŸ“Š Test Accuracy: {val_accuracy*100:.2f}%')
print(f'ðŸ’¥ Test Loss: {val_loss:.4f}')
# accuracy: 0.9599 - loss: 0.1058
#ðŸ“Š Test Accuracy: 89.89%
#ðŸ’¥ Test Loss: 0.2576

plot_training_history_with_plotly(history)

"""## CIFAKE2"""

model2 = Sequential()
model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32,32,3)))
model2.add(MaxPooling2D(padding='same'))
model2.add(BatchNormalization())
model2.add(Conv2D(32, (3, 3), activation='relu'))
model2.add(MaxPooling2D(padding='same'))
model2.add(Dropout(0.3))
model2.add(Flatten())
model2.add(Dense(64, activation='relu'))
model2.add(Dense(1, activation='sigmoid'))  # Ù„Ùˆ ÙƒØ§Ù† Ø¹Ù†Ø¯Ùƒ ØªØµÙ†ÙŠÙ Ø«Ù†Ø§Ø¦ÙŠ

model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
early2 = callbacks.EarlyStopping(monitor='val_accuracy', verbose=1, mode='auto', restore_best_weights=True, patience=7)

# Display model summary
model2.summary()

model2.build()
visualkeras.layered_view(model2, scale_xy=5 ,legend=True)

model2_history = model2.fit(
    train_generator,
    epochs=100,
    batch_size= 32,
    validation_data=val_generator,
    verbose=1 ,
    callbacks=[early2,checkpoint]
)

model.save('CIFAKE2.keras')

"""### Evaluation of Model2 "CIFAKE2"
"""

model2 = load_model('/content/CIFAKE2.keras')

val_loss, val_accuracy = model2.evaluate(test_generator)
print(f'ðŸ“Š Test Accuracy: {val_accuracy*100:.2f}%')
print(f'ðŸ’¥ Test Loss: {val_loss:.4f}')
# accuracy: 0.9528 - loss: 0.1224
#ðŸ“Š Test Accuracy: 88.82%
#ðŸ’¥ Test Loss: 0.2832

plot_training_history_with_plotly(model2_history)

"""# Some Visualization"""

models = {
    'Model_1': model,
    'Model_2': model2
}

for name, model in models.items():
    print(f"Results for {name}:")

    y_pred_probs = model.predict(test_generator)
    y_pred = (y_pred_probs > 0.5).astype(int).flatten()
    y_true = test_generator.classes

    print(classification_report(y_true, y_pred, target_names=['FAKE', 'REAL']))

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['FAKE', 'REAL'], yticklabels=['FAKE', 'REAL'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix for {name}')
    plt.show()

import os

models = {
    'Model_1': model,
    'Model_2': model2
}

y_true = test_generator.classes
class_labels = list(test_generator.class_indices.keys())
filenames = test_generator.filenames

for name, model in models.items():
    print(f"\nShowing wrong predictions for {name}:")

    y_pred_probs = model.predict(test_generator)
    y_pred = (y_pred_probs > 0.5).astype(int).flatten()

    wrong_preds = np.where(y_pred != y_true)[0]

    plt.figure(figsize=(15, 10))
    for i, idx in enumerate(wrong_preds[:6]):  # Ø§Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 6 Ø£ØºÙ„Ø§Ø·
        img_path = os.path.join(test_generator.directory, filenames[idx])
        img = plt.imread(img_path)

        true_label = class_labels[y_true[idx]]
        pred_label = class_labels[y_pred[idx]]

        plt.subplot(3, 3, i+1)
        plt.imshow(img)
        plt.axis('off')
        plt.title(f'ðŸš« True: {true_label} | Pred: {pred_label}', color='black')

    plt.suptitle(f'Examples of mistakes - {name}', fontsize=16)
    plt.tight_layout()
    plt.show()